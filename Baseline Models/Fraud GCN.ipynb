{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc3bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relational Graph Convolutional NetworkÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a51c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "from functools import partial\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import GATConv\n",
    "import numpy as np\n",
    "from pygod.utils import load_data as pygod_load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785209d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat,\n",
    "        out_feat,\n",
    "        num_rels,\n",
    "        num_bases=-1,\n",
    "        bias=None,\n",
    "        activation=None,\n",
    "        is_input_layer=False,\n",
    "    ):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.Tensor(self.num_bases, self.in_feat, self.out_feat)\n",
    "        )\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(\n",
    "                torch.Tensor(self.num_rels, self.num_bases)\n",
    "            )\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(\n",
    "            self.weight, gain=nn.init.calculate_gain(\"relu\")\n",
    "        )\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(\n",
    "                self.w_comp, gain=nn.init.calculate_gain(\"relu\")\n",
    "            )\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(\n",
    "                self.bias, gain=nn.init.calculate_gain(\"relu\")\n",
    "            )\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(\n",
    "                self.in_feat, self.num_bases, self.out_feat\n",
    "            )\n",
    "            weight = torch.matmul(self.w_comp, weight).view(\n",
    "                self.num_rels, self.in_feat, self.out_feat\n",
    "            )\n",
    "        else:\n",
    "            weight = self.weight\n",
    "        if self.is_input_layer:\n",
    "\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                embed = weight.view(-1, self.out_feat)\n",
    "                index = edges.data[dgl.ETYPE] * self.in_feat + edges.src[\"id\"]\n",
    "                return {\"msg\": embed[index] * edges.data[\"norm\"]}\n",
    "\n",
    "        else:\n",
    "\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data[dgl.ETYPE]]\n",
    "                msg = torch.bmm(edges.src[\"h\"].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data[\"norm\"]\n",
    "                return {\"msg\": msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data[\"h\"]\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {\"h\": h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg=\"msg\", out=\"h\"), apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff0801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes,\n",
    "        h_dim,\n",
    "        out_dim,\n",
    "        num_rels,\n",
    "        num_bases=-1,\n",
    "        num_hidden_layers=1,\n",
    "    ):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for _ in range(self.num_hidden_layers):\n",
    "            h2h = self.build_hidden_layer()\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        features = torch.arange(self.num_nodes)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(\n",
    "            self.num_nodes,\n",
    "            self.h_dim,\n",
    "            self.num_rels,\n",
    "            self.num_bases,\n",
    "            activation=F.relu,\n",
    "            is_input_layer=True,\n",
    "        )\n",
    "\n",
    "    def build_hidden_layer(self):\n",
    "        return RGCNLayer(\n",
    "            self.h_dim,\n",
    "            self.h_dim,\n",
    "            self.num_rels,\n",
    "            self.num_bases,\n",
    "            activation=F.relu,\n",
    "        )\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(\n",
    "            self.h_dim,\n",
    "            self.out_dim,\n",
    "            self.num_rels,\n",
    "            self.num_bases,\n",
    "            activation=partial(F.softmax, dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            g.ndata[\"id\"] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop(\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eccca5",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95abbf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import FraudAmazonDataset\n",
    "amazon = FraudAmazonDataset()\n",
    "g1 = amazon[0]\n",
    "num_classes = amazon.num_classes\n",
    "feat = g1.ndata['feature']\n",
    "label = g1.ndata['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d8034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = g1.nodes['user'].data['train_mask']\n",
    "test_mask = g1.nodes['user'].data['test_mask']\n",
    "train_idx = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "test_idx = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
    "labels = g1.nodes['user'].data.pop(\"label\")\n",
    "num_rels = len(g1.canonical_etypes)\n",
    "num_classes = amazon.num_classes\n",
    "\n",
    "# normalization factor\n",
    "for cetype in g1.canonical_etypes:\n",
    "    g1.edges[cetype].data[\"norm\"] = dgl.norm_by_dst(g1, cetype).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b97afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_hidden = 16  # number of hidden units\n",
    "n_bases = -1  # use number of relations as number of bases\n",
    "n_hidden_layers = 0  # use 1 input layer, 1 output layer, no hidden layer\n",
    "n_epochs = 100  # epochs to train\n",
    "lr = 0.01  # learning rate\n",
    "l2norm = 0  # L2 norm coefficient\n",
    "\n",
    "# create graph\n",
    "g = dgl.to_homogeneous(g1, edata=[\"norm\"])\n",
    "node_ids = torch.arange(g.num_nodes())\n",
    "#target_idx = node_ids[g1.ndata[dgl.NTYPE] == category_id]\n",
    "\n",
    "# create model\n",
    "model = Model(\n",
    "    g.num_nodes(),\n",
    "    n_hidden,\n",
    "    num_classes,\n",
    "    num_rels,\n",
    "    num_bases=n_bases,\n",
    "    num_hidden_layers=n_hidden_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a7b493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Epoch 00000 | Train Accuracy: 0.7498 | Train Loss: 0.6929 | Validation Accuracy: 0.7432 | Validation loss: 0.6929\n",
      "Epoch 00001 | Train Accuracy: 0.9054 | Train Loss: 0.6544 | Validation Accuracy: 0.8936 | Validation loss: 0.6562\n",
      "Epoch 00002 | Train Accuracy: 0.9054 | Train Loss: 0.6156 | Validation Accuracy: 0.8936 | Validation loss: 0.6192\n",
      "Epoch 00003 | Train Accuracy: 0.9054 | Train Loss: 0.5761 | Validation Accuracy: 0.8936 | Validation loss: 0.5817\n",
      "Epoch 00004 | Train Accuracy: 0.9054 | Train Loss: 0.5385 | Validation Accuracy: 0.8936 | Validation loss: 0.5459\n",
      "Epoch 00005 | Train Accuracy: 0.9054 | Train Loss: 0.5050 | Validation Accuracy: 0.8936 | Validation loss: 0.5141\n",
      "Epoch 00006 | Train Accuracy: 0.9054 | Train Loss: 0.4772 | Validation Accuracy: 0.8936 | Validation loss: 0.4877\n",
      "Epoch 00007 | Train Accuracy: 0.9054 | Train Loss: 0.4556 | Validation Accuracy: 0.8936 | Validation loss: 0.4672\n",
      "Epoch 00008 | Train Accuracy: 0.9054 | Train Loss: 0.4397 | Validation Accuracy: 0.8936 | Validation loss: 0.4520\n",
      "Epoch 00009 | Train Accuracy: 0.9054 | Train Loss: 0.4286 | Validation Accuracy: 0.8936 | Validation loss: 0.4413\n",
      "Epoch 00010 | Train Accuracy: 0.9054 | Train Loss: 0.4211 | Validation Accuracy: 0.8936 | Validation loss: 0.4341\n",
      "Epoch 00011 | Train Accuracy: 0.9054 | Train Loss: 0.4162 | Validation Accuracy: 0.8936 | Validation loss: 0.4292\n",
      "Epoch 00012 | Train Accuracy: 0.9054 | Train Loss: 0.4130 | Validation Accuracy: 0.8936 | Validation loss: 0.4260\n",
      "Epoch 00013 | Train Accuracy: 0.9054 | Train Loss: 0.4110 | Validation Accuracy: 0.8936 | Validation loss: 0.4239\n",
      "Epoch 00014 | Train Accuracy: 0.9054 | Train Loss: 0.4096 | Validation Accuracy: 0.8936 | Validation loss: 0.4225\n",
      "Epoch 00015 | Train Accuracy: 0.9054 | Train Loss: 0.4088 | Validation Accuracy: 0.8936 | Validation loss: 0.4216\n",
      "Epoch 00016 | Train Accuracy: 0.9054 | Train Loss: 0.4082 | Validation Accuracy: 0.8936 | Validation loss: 0.4210\n",
      "Epoch 00017 | Train Accuracy: 0.9054 | Train Loss: 0.4079 | Validation Accuracy: 0.8936 | Validation loss: 0.4206\n",
      "Epoch 00018 | Train Accuracy: 0.9054 | Train Loss: 0.4076 | Validation Accuracy: 0.8936 | Validation loss: 0.4203\n",
      "Epoch 00019 | Train Accuracy: 0.9056 | Train Loss: 0.4075 | Validation Accuracy: 0.8936 | Validation loss: 0.4201\n",
      "Epoch 00020 | Train Accuracy: 0.9056 | Train Loss: 0.4074 | Validation Accuracy: 0.8936 | Validation loss: 0.4199\n",
      "Epoch 00021 | Train Accuracy: 0.9056 | Train Loss: 0.4073 | Validation Accuracy: 0.8936 | Validation loss: 0.4198\n",
      "Epoch 00022 | Train Accuracy: 0.9056 | Train Loss: 0.4072 | Validation Accuracy: 0.8936 | Validation loss: 0.4198\n",
      "Epoch 00023 | Train Accuracy: 0.9056 | Train Loss: 0.4072 | Validation Accuracy: 0.8936 | Validation loss: 0.4197\n",
      "Epoch 00024 | Train Accuracy: 0.9056 | Train Loss: 0.4072 | Validation Accuracy: 0.8936 | Validation loss: 0.4197\n",
      "Epoch 00025 | Train Accuracy: 0.9056 | Train Loss: 0.4071 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00026 | Train Accuracy: 0.9056 | Train Loss: 0.4071 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00027 | Train Accuracy: 0.9056 | Train Loss: 0.4071 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00028 | Train Accuracy: 0.9056 | Train Loss: 0.4071 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00029 | Train Accuracy: 0.9056 | Train Loss: 0.4070 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00030 | Train Accuracy: 0.9056 | Train Loss: 0.4070 | Validation Accuracy: 0.8936 | Validation loss: 0.4196\n",
      "Epoch 00031 | Train Accuracy: 0.9056 | Train Loss: 0.4070 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00032 | Train Accuracy: 0.9057 | Train Loss: 0.4070 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00033 | Train Accuracy: 0.9057 | Train Loss: 0.4069 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00034 | Train Accuracy: 0.9057 | Train Loss: 0.4069 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00035 | Train Accuracy: 0.9057 | Train Loss: 0.4068 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00036 | Train Accuracy: 0.9057 | Train Loss: 0.4068 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00037 | Train Accuracy: 0.9057 | Train Loss: 0.4067 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00038 | Train Accuracy: 0.9057 | Train Loss: 0.4067 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00039 | Train Accuracy: 0.9057 | Train Loss: 0.4066 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00041 | Train Accuracy: 0.9057 | Train Loss: 0.4065 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00042 | Train Accuracy: 0.9059 | Train Loss: 0.4064 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00043 | Train Accuracy: 0.9061 | Train Loss: 0.4064 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00044 | Train Accuracy: 0.9061 | Train Loss: 0.4063 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00045 | Train Accuracy: 0.9061 | Train Loss: 0.4062 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00046 | Train Accuracy: 0.9061 | Train Loss: 0.4061 | Validation Accuracy: 0.8930 | Validation loss: 0.4195\n",
      "Epoch 00047 | Train Accuracy: 0.9061 | Train Loss: 0.4060 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00048 | Train Accuracy: 0.9061 | Train Loss: 0.4058 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00049 | Train Accuracy: 0.9062 | Train Loss: 0.4057 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00050 | Train Accuracy: 0.9064 | Train Loss: 0.4055 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00051 | Train Accuracy: 0.9064 | Train Loss: 0.4054 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00052 | Train Accuracy: 0.9064 | Train Loss: 0.4052 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00053 | Train Accuracy: 0.9067 | Train Loss: 0.4050 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00054 | Train Accuracy: 0.9069 | Train Loss: 0.4048 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00055 | Train Accuracy: 0.9077 | Train Loss: 0.4045 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00056 | Train Accuracy: 0.9079 | Train Loss: 0.4043 | Validation Accuracy: 0.8936 | Validation loss: 0.4195\n",
      "Epoch 00057 | Train Accuracy: 0.9081 | Train Loss: 0.4040 | Validation Accuracy: 0.8936 | Validation loss: 0.4194\n",
      "Epoch 00058 | Train Accuracy: 0.9084 | Train Loss: 0.4038 | Validation Accuracy: 0.8936 | Validation loss: 0.4194\n",
      "Epoch 00059 | Train Accuracy: 0.9090 | Train Loss: 0.4035 | Validation Accuracy: 0.8930 | Validation loss: 0.4194\n",
      "Epoch 00062 | Train Accuracy: 0.9095 | Train Loss: 0.4027 | Validation Accuracy: 0.8930 | Validation loss: 0.4192\n",
      "Epoch 00063 | Train Accuracy: 0.9102 | Train Loss: 0.4024 | Validation Accuracy: 0.8936 | Validation loss: 0.4191\n",
      "Epoch 00064 | Train Accuracy: 0.9102 | Train Loss: 0.4022 | Validation Accuracy: 0.8942 | Validation loss: 0.4190\n",
      "Epoch 00065 | Train Accuracy: 0.9104 | Train Loss: 0.4019 | Validation Accuracy: 0.8942 | Validation loss: 0.4190\n",
      "Epoch 00066 | Train Accuracy: 0.9110 | Train Loss: 0.4016 | Validation Accuracy: 0.8942 | Validation loss: 0.4189\n",
      "Epoch 00067 | Train Accuracy: 0.9112 | Train Loss: 0.4013 | Validation Accuracy: 0.8942 | Validation loss: 0.4189\n",
      "Epoch 00068 | Train Accuracy: 0.9112 | Train Loss: 0.4011 | Validation Accuracy: 0.8953 | Validation loss: 0.4189\n",
      "Epoch 00069 | Train Accuracy: 0.9112 | Train Loss: 0.4007 | Validation Accuracy: 0.8953 | Validation loss: 0.4189\n",
      "Epoch 00070 | Train Accuracy: 0.9115 | Train Loss: 0.4004 | Validation Accuracy: 0.8947 | Validation loss: 0.4189\n",
      "Epoch 00071 | Train Accuracy: 0.9119 | Train Loss: 0.4000 | Validation Accuracy: 0.8947 | Validation loss: 0.4190\n",
      "Epoch 00072 | Train Accuracy: 0.9122 | Train Loss: 0.3996 | Validation Accuracy: 0.8936 | Validation loss: 0.4190\n",
      "Epoch 00073 | Train Accuracy: 0.9125 | Train Loss: 0.3992 | Validation Accuracy: 0.8936 | Validation loss: 0.4191\n",
      "Epoch 00074 | Train Accuracy: 0.9128 | Train Loss: 0.3988 | Validation Accuracy: 0.8930 | Validation loss: 0.4192\n",
      "Epoch 00075 | Train Accuracy: 0.9142 | Train Loss: 0.3983 | Validation Accuracy: 0.8924 | Validation loss: 0.4193\n",
      "Epoch 00076 | Train Accuracy: 0.9145 | Train Loss: 0.3978 | Validation Accuracy: 0.8930 | Validation loss: 0.4193\n",
      "Epoch 00077 | Train Accuracy: 0.9158 | Train Loss: 0.3972 | Validation Accuracy: 0.8924 | Validation loss: 0.4194\n",
      "Epoch 00078 | Train Accuracy: 0.9162 | Train Loss: 0.3967 | Validation Accuracy: 0.8924 | Validation loss: 0.4194\n",
      "Epoch 00079 | Train Accuracy: 0.9171 | Train Loss: 0.3961 | Validation Accuracy: 0.8918 | Validation loss: 0.4194\n",
      "Epoch 00080 | Train Accuracy: 0.9180 | Train Loss: 0.3955 | Validation Accuracy: 0.8918 | Validation loss: 0.4194\n",
      "Epoch 00081 | Train Accuracy: 0.9186 | Train Loss: 0.3949 | Validation Accuracy: 0.8918 | Validation loss: 0.4193\n",
      "Epoch 00082 | Train Accuracy: 0.9193 | Train Loss: 0.3943 | Validation Accuracy: 0.8918 | Validation loss: 0.4192\n",
      "Epoch 00083 | Train Accuracy: 0.9191 | Train Loss: 0.3937 | Validation Accuracy: 0.8918 | Validation loss: 0.4190\n",
      "Epoch 00084 | Train Accuracy: 0.9200 | Train Loss: 0.3932 | Validation Accuracy: 0.8924 | Validation loss: 0.4187\n",
      "Epoch 00085 | Train Accuracy: 0.9210 | Train Loss: 0.3926 | Validation Accuracy: 0.8913 | Validation loss: 0.4184\n",
      "Epoch 00086 | Train Accuracy: 0.9211 | Train Loss: 0.3920 | Validation Accuracy: 0.8913 | Validation loss: 0.4181\n",
      "Epoch 00087 | Train Accuracy: 0.9213 | Train Loss: 0.3914 | Validation Accuracy: 0.8907 | Validation loss: 0.4177\n",
      "Epoch 00088 | Train Accuracy: 0.9219 | Train Loss: 0.3906 | Validation Accuracy: 0.8907 | Validation loss: 0.4173\n",
      "Epoch 00089 | Train Accuracy: 0.9224 | Train Loss: 0.3898 | Validation Accuracy: 0.8913 | Validation loss: 0.4168\n",
      "Epoch 00090 | Train Accuracy: 0.9233 | Train Loss: 0.3888 | Validation Accuracy: 0.8918 | Validation loss: 0.4162\n",
      "Epoch 00091 | Train Accuracy: 0.9241 | Train Loss: 0.3877 | Validation Accuracy: 0.8942 | Validation loss: 0.4156\n",
      "Epoch 00092 | Train Accuracy: 0.9253 | Train Loss: 0.3864 | Validation Accuracy: 0.8930 | Validation loss: 0.4148\n",
      "Epoch 00093 | Train Accuracy: 0.9262 | Train Loss: 0.3851 | Validation Accuracy: 0.8947 | Validation loss: 0.4139\n",
      "Epoch 00094 | Train Accuracy: 0.9286 | Train Loss: 0.3837 | Validation Accuracy: 0.8971 | Validation loss: 0.4130\n",
      "Epoch 00095 | Train Accuracy: 0.9304 | Train Loss: 0.3823 | Validation Accuracy: 0.8988 | Validation loss: 0.4122\n",
      "Epoch 00096 | Train Accuracy: 0.9330 | Train Loss: 0.3810 | Validation Accuracy: 0.9011 | Validation loss: 0.4116\n",
      "Epoch 00097 | Train Accuracy: 0.9352 | Train Loss: 0.3797 | Validation Accuracy: 0.9028 | Validation loss: 0.4110\n",
      "Epoch 00098 | Train Accuracy: 0.9373 | Train Loss: 0.3782 | Validation Accuracy: 0.9046 | Validation loss: 0.4104\n",
      "Epoch 00099 | Train Accuracy: 0.9386 | Train Loss: 0.3767 | Validation Accuracy: 0.9051 | Validation loss: 0.4098\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "\n",
    "print(\"start training...\")\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model.forward(g)\n",
    "    #logits = logits[target_idx]\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc = torch.sum(logits[train_idx].argmax(dim=1) == labels[train_idx])\n",
    "    train_acc = train_acc.item() / len(train_idx)\n",
    "    val_loss = F.cross_entropy(logits[test_idx], labels[test_idx])\n",
    "    val_acc = torch.sum(logits[test_idx].argmax(dim=1) == labels[test_idx])\n",
    "    val_acc = val_acc.item() / len(test_idx)\n",
    "    print(\n",
    "        \"Epoch {:05d} | \".format(epoch)\n",
    "        + \"Train Accuracy: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "            train_acc, loss.item()\n",
    "        )\n",
    "        + \"Validation Accuracy: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "            val_acc, val_loss.item()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e2d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.8125633178556353\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# After training, when evaluating on test data:\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(g)\n",
    "    probabilities = F.softmax(logits[test_idx], dim=1)  # Convert logits to probabilities\n",
    "    # Assuming your positive class is 1 (adjust accordingly if it's different)\n",
    "    positive_probabilities = probabilities[:, 1]  # Get probabilities for the positive class\n",
    "    # Calculate ROC-AUC\n",
    "    roc_auc = roc_auc_score(labels[test_idx].cpu(), positive_probabilities.cpu())\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d906fd",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7f5a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import FraudYelpDataset\n",
    "yelp = FraudYelpDataset()\n",
    "g2 = yelp[0]\n",
    "num_classes = yelp.num_classes\n",
    "feat = g2.ndata['feature']\n",
    "label = g2.ndata['label']\n",
    "train_mask = g2.ndata['train_mask']\n",
    "test_mask = g2.ndata['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06116eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = g2.nodes['review'].data['train_mask']\n",
    "test_mask = g2.nodes['review'].data['test_mask']\n",
    "train_idx = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "test_idx = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
    "labels = g2.nodes['review'].data.pop(\"label\")\n",
    "num_rels = len(g2.canonical_etypes)\n",
    "num_classes = amazon.num_classes\n",
    "\n",
    "# normalization factor\n",
    "for cetype in g2.canonical_etypes:\n",
    "    g2.edges[cetype].data[\"norm\"] = dgl.norm_by_dst(g2, cetype).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fdc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_hidden = 16  # number of hidden units\n",
    "n_bases = -1  # use number of relations as number of bases\n",
    "n_hidden_layers = 0  # use 1 input layer, 1 output layer, no hidden layer\n",
    "n_epochs = 100  # epochs to train\n",
    "lr = 0.01  # learning rate\n",
    "l2norm = 0  # L2 norm coefficient\n",
    "\n",
    "# create graph\n",
    "g = dgl.to_homogeneous(g2, edata=[\"norm\"])\n",
    "node_ids = torch.arange(g.num_nodes())\n",
    "#target_idx = node_ids[g2.ndata[dgl.NTYPE] == category_id]\n",
    "\n",
    "# create model\n",
    "model = Model(\n",
    "    g.num_nodes(),\n",
    "    n_hidden,\n",
    "    num_classes,\n",
    "    num_rels,\n",
    "    num_bases=n_bases,\n",
    "    num_hidden_layers=n_hidden_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50db23c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Epoch 00000 | Train Accuracy: 0.5938 | Train Loss: 0.6931 | Validation Accuracy: 0.5978 | Validation loss: 0.6931\n",
      "Epoch 00001 | Train Accuracy: 0.8583 | Train Loss: 0.6724 | Validation Accuracy: 0.8610 | Validation loss: 0.6733\n",
      "Epoch 00002 | Train Accuracy: 0.8583 | Train Loss: 0.6490 | Validation Accuracy: 0.8610 | Validation loss: 0.6512\n",
      "Epoch 00003 | Train Accuracy: 0.8582 | Train Loss: 0.6236 | Validation Accuracy: 0.8606 | Validation loss: 0.6268\n",
      "Epoch 00004 | Train Accuracy: 0.8578 | Train Loss: 0.5972 | Validation Accuracy: 0.8604 | Validation loss: 0.6013\n",
      "Epoch 00005 | Train Accuracy: 0.8576 | Train Loss: 0.5713 | Validation Accuracy: 0.8601 | Validation loss: 0.5758\n",
      "Epoch 00006 | Train Accuracy: 0.8574 | Train Loss: 0.5469 | Validation Accuracy: 0.8599 | Validation loss: 0.5514\n",
      "Epoch 00007 | Train Accuracy: 0.8572 | Train Loss: 0.5252 | Validation Accuracy: 0.8600 | Validation loss: 0.5294\n",
      "Epoch 00008 | Train Accuracy: 0.8575 | Train Loss: 0.5068 | Validation Accuracy: 0.8603 | Validation loss: 0.5106\n",
      "Epoch 00009 | Train Accuracy: 0.8576 | Train Loss: 0.4921 | Validation Accuracy: 0.8603 | Validation loss: 0.4952\n",
      "Epoch 00010 | Train Accuracy: 0.8579 | Train Loss: 0.4808 | Validation Accuracy: 0.8602 | Validation loss: 0.4831\n",
      "Epoch 00011 | Train Accuracy: 0.8582 | Train Loss: 0.4725 | Validation Accuracy: 0.8602 | Validation loss: 0.4741\n",
      "Epoch 00012 | Train Accuracy: 0.8583 | Train Loss: 0.4665 | Validation Accuracy: 0.8605 | Validation loss: 0.4675\n",
      "Epoch 00013 | Train Accuracy: 0.8583 | Train Loss: 0.4622 | Validation Accuracy: 0.8606 | Validation loss: 0.4628\n",
      "Epoch 00014 | Train Accuracy: 0.8585 | Train Loss: 0.4593 | Validation Accuracy: 0.8611 | Validation loss: 0.4594\n",
      "Epoch 00015 | Train Accuracy: 0.8586 | Train Loss: 0.4572 | Validation Accuracy: 0.8610 | Validation loss: 0.4570\n",
      "Epoch 00016 | Train Accuracy: 0.8590 | Train Loss: 0.4556 | Validation Accuracy: 0.8611 | Validation loss: 0.4553\n",
      "Epoch 00017 | Train Accuracy: 0.8592 | Train Loss: 0.4545 | Validation Accuracy: 0.8612 | Validation loss: 0.4540\n",
      "Epoch 00018 | Train Accuracy: 0.8594 | Train Loss: 0.4536 | Validation Accuracy: 0.8612 | Validation loss: 0.4531\n",
      "Epoch 00019 | Train Accuracy: 0.8598 | Train Loss: 0.4529 | Validation Accuracy: 0.8617 | Validation loss: 0.4524\n",
      "Epoch 00020 | Train Accuracy: 0.8604 | Train Loss: 0.4524 | Validation Accuracy: 0.8622 | Validation loss: 0.4519\n",
      "Epoch 00021 | Train Accuracy: 0.8606 | Train Loss: 0.4519 | Validation Accuracy: 0.8624 | Validation loss: 0.4515\n",
      "Epoch 00022 | Train Accuracy: 0.8608 | Train Loss: 0.4514 | Validation Accuracy: 0.8624 | Validation loss: 0.4511\n",
      "Epoch 00023 | Train Accuracy: 0.8610 | Train Loss: 0.4510 | Validation Accuracy: 0.8625 | Validation loss: 0.4509\n",
      "Epoch 00024 | Train Accuracy: 0.8614 | Train Loss: 0.4506 | Validation Accuracy: 0.8627 | Validation loss: 0.4507\n",
      "Epoch 00025 | Train Accuracy: 0.8616 | Train Loss: 0.4502 | Validation Accuracy: 0.8627 | Validation loss: 0.4505\n",
      "Epoch 00026 | Train Accuracy: 0.8622 | Train Loss: 0.4498 | Validation Accuracy: 0.8627 | Validation loss: 0.4504\n",
      "Epoch 00027 | Train Accuracy: 0.8624 | Train Loss: 0.4495 | Validation Accuracy: 0.8623 | Validation loss: 0.4503\n",
      "Epoch 00028 | Train Accuracy: 0.8627 | Train Loss: 0.4491 | Validation Accuracy: 0.8619 | Validation loss: 0.4503\n",
      "Epoch 00029 | Train Accuracy: 0.8630 | Train Loss: 0.4488 | Validation Accuracy: 0.8619 | Validation loss: 0.4502\n",
      "Epoch 00030 | Train Accuracy: 0.8634 | Train Loss: 0.4484 | Validation Accuracy: 0.8617 | Validation loss: 0.4502\n",
      "Epoch 00031 | Train Accuracy: 0.8638 | Train Loss: 0.4481 | Validation Accuracy: 0.8621 | Validation loss: 0.4502\n",
      "Epoch 00032 | Train Accuracy: 0.8643 | Train Loss: 0.4477 | Validation Accuracy: 0.8618 | Validation loss: 0.4502\n",
      "Epoch 00033 | Train Accuracy: 0.8647 | Train Loss: 0.4474 | Validation Accuracy: 0.8618 | Validation loss: 0.4502\n",
      "Epoch 00034 | Train Accuracy: 0.8654 | Train Loss: 0.4470 | Validation Accuracy: 0.8622 | Validation loss: 0.4501\n",
      "Epoch 00035 | Train Accuracy: 0.8656 | Train Loss: 0.4467 | Validation Accuracy: 0.8621 | Validation loss: 0.4501\n",
      "Epoch 00036 | Train Accuracy: 0.8661 | Train Loss: 0.4463 | Validation Accuracy: 0.8621 | Validation loss: 0.4500\n",
      "Epoch 00037 | Train Accuracy: 0.8667 | Train Loss: 0.4459 | Validation Accuracy: 0.8623 | Validation loss: 0.4499\n",
      "Epoch 00038 | Train Accuracy: 0.8669 | Train Loss: 0.4455 | Validation Accuracy: 0.8626 | Validation loss: 0.4499\n",
      "Epoch 00039 | Train Accuracy: 0.8670 | Train Loss: 0.4451 | Validation Accuracy: 0.8634 | Validation loss: 0.4498\n",
      "Epoch 00040 | Train Accuracy: 0.8674 | Train Loss: 0.4447 | Validation Accuracy: 0.8639 | Validation loss: 0.4498\n",
      "Epoch 00041 | Train Accuracy: 0.8676 | Train Loss: 0.4443 | Validation Accuracy: 0.8634 | Validation loss: 0.4497\n",
      "Epoch 00042 | Train Accuracy: 0.8680 | Train Loss: 0.4439 | Validation Accuracy: 0.8630 | Validation loss: 0.4497\n",
      "Epoch 00043 | Train Accuracy: 0.8683 | Train Loss: 0.4435 | Validation Accuracy: 0.8629 | Validation loss: 0.4498\n",
      "Epoch 00044 | Train Accuracy: 0.8687 | Train Loss: 0.4431 | Validation Accuracy: 0.8625 | Validation loss: 0.4498\n",
      "Epoch 00045 | Train Accuracy: 0.8695 | Train Loss: 0.4427 | Validation Accuracy: 0.8627 | Validation loss: 0.4499\n",
      "Epoch 00046 | Train Accuracy: 0.8698 | Train Loss: 0.4422 | Validation Accuracy: 0.8626 | Validation loss: 0.4500\n",
      "Epoch 00047 | Train Accuracy: 0.8702 | Train Loss: 0.4418 | Validation Accuracy: 0.8624 | Validation loss: 0.4501\n",
      "Epoch 00048 | Train Accuracy: 0.8707 | Train Loss: 0.4413 | Validation Accuracy: 0.8624 | Validation loss: 0.4503\n",
      "Epoch 00049 | Train Accuracy: 0.8713 | Train Loss: 0.4408 | Validation Accuracy: 0.8617 | Validation loss: 0.4504\n",
      "Epoch 00050 | Train Accuracy: 0.8721 | Train Loss: 0.4404 | Validation Accuracy: 0.8614 | Validation loss: 0.4507\n",
      "Epoch 00051 | Train Accuracy: 0.8729 | Train Loss: 0.4399 | Validation Accuracy: 0.8612 | Validation loss: 0.4509\n",
      "Epoch 00052 | Train Accuracy: 0.8735 | Train Loss: 0.4394 | Validation Accuracy: 0.8610 | Validation loss: 0.4512\n",
      "Epoch 00053 | Train Accuracy: 0.8741 | Train Loss: 0.4390 | Validation Accuracy: 0.8600 | Validation loss: 0.4515\n",
      "Epoch 00054 | Train Accuracy: 0.8745 | Train Loss: 0.4385 | Validation Accuracy: 0.8596 | Validation loss: 0.4518\n",
      "Epoch 00055 | Train Accuracy: 0.8751 | Train Loss: 0.4381 | Validation Accuracy: 0.8597 | Validation loss: 0.4521\n",
      "Epoch 00056 | Train Accuracy: 0.8756 | Train Loss: 0.4376 | Validation Accuracy: 0.8593 | Validation loss: 0.4524\n",
      "Epoch 00057 | Train Accuracy: 0.8760 | Train Loss: 0.4372 | Validation Accuracy: 0.8594 | Validation loss: 0.4527\n",
      "Epoch 00058 | Train Accuracy: 0.8764 | Train Loss: 0.4367 | Validation Accuracy: 0.8589 | Validation loss: 0.4530\n",
      "Epoch 00059 | Train Accuracy: 0.8768 | Train Loss: 0.4362 | Validation Accuracy: 0.8584 | Validation loss: 0.4533\n",
      "Epoch 00060 | Train Accuracy: 0.8773 | Train Loss: 0.4356 | Validation Accuracy: 0.8580 | Validation loss: 0.4536\n",
      "Epoch 00061 | Train Accuracy: 0.8779 | Train Loss: 0.4351 | Validation Accuracy: 0.8577 | Validation loss: 0.4538\n",
      "Epoch 00062 | Train Accuracy: 0.8785 | Train Loss: 0.4345 | Validation Accuracy: 0.8575 | Validation loss: 0.4540\n",
      "Epoch 00063 | Train Accuracy: 0.8794 | Train Loss: 0.4339 | Validation Accuracy: 0.8572 | Validation loss: 0.4542\n",
      "Epoch 00064 | Train Accuracy: 0.8802 | Train Loss: 0.4332 | Validation Accuracy: 0.8577 | Validation loss: 0.4544\n",
      "Epoch 00065 | Train Accuracy: 0.8811 | Train Loss: 0.4326 | Validation Accuracy: 0.8579 | Validation loss: 0.4545\n",
      "Epoch 00066 | Train Accuracy: 0.8821 | Train Loss: 0.4319 | Validation Accuracy: 0.8573 | Validation loss: 0.4547\n",
      "Epoch 00067 | Train Accuracy: 0.8826 | Train Loss: 0.4312 | Validation Accuracy: 0.8573 | Validation loss: 0.4548\n",
      "Epoch 00068 | Train Accuracy: 0.8834 | Train Loss: 0.4305 | Validation Accuracy: 0.8574 | Validation loss: 0.4550\n",
      "Epoch 00069 | Train Accuracy: 0.8844 | Train Loss: 0.4298 | Validation Accuracy: 0.8572 | Validation loss: 0.4552\n",
      "Epoch 00070 | Train Accuracy: 0.8850 | Train Loss: 0.4290 | Validation Accuracy: 0.8567 | Validation loss: 0.4554\n",
      "Epoch 00071 | Train Accuracy: 0.8857 | Train Loss: 0.4283 | Validation Accuracy: 0.8559 | Validation loss: 0.4557\n",
      "Epoch 00072 | Train Accuracy: 0.8863 | Train Loss: 0.4275 | Validation Accuracy: 0.8554 | Validation loss: 0.4560\n",
      "Epoch 00073 | Train Accuracy: 0.8870 | Train Loss: 0.4268 | Validation Accuracy: 0.8552 | Validation loss: 0.4563\n",
      "Epoch 00074 | Train Accuracy: 0.8881 | Train Loss: 0.4260 | Validation Accuracy: 0.8548 | Validation loss: 0.4567\n",
      "Epoch 00075 | Train Accuracy: 0.8890 | Train Loss: 0.4252 | Validation Accuracy: 0.8536 | Validation loss: 0.4571\n",
      "Epoch 00076 | Train Accuracy: 0.8901 | Train Loss: 0.4244 | Validation Accuracy: 0.8537 | Validation loss: 0.4576\n",
      "Epoch 00077 | Train Accuracy: 0.8913 | Train Loss: 0.4236 | Validation Accuracy: 0.8539 | Validation loss: 0.4580\n",
      "Epoch 00078 | Train Accuracy: 0.8918 | Train Loss: 0.4228 | Validation Accuracy: 0.8531 | Validation loss: 0.4585\n",
      "Epoch 00079 | Train Accuracy: 0.8932 | Train Loss: 0.4220 | Validation Accuracy: 0.8528 | Validation loss: 0.4590\n",
      "Epoch 00080 | Train Accuracy: 0.8944 | Train Loss: 0.4212 | Validation Accuracy: 0.8522 | Validation loss: 0.4595\n",
      "Epoch 00081 | Train Accuracy: 0.8955 | Train Loss: 0.4204 | Validation Accuracy: 0.8514 | Validation loss: 0.4599\n",
      "Epoch 00082 | Train Accuracy: 0.8964 | Train Loss: 0.4195 | Validation Accuracy: 0.8512 | Validation loss: 0.4602\n",
      "Epoch 00083 | Train Accuracy: 0.8971 | Train Loss: 0.4187 | Validation Accuracy: 0.8507 | Validation loss: 0.4606\n",
      "Epoch 00084 | Train Accuracy: 0.8981 | Train Loss: 0.4178 | Validation Accuracy: 0.8505 | Validation loss: 0.4608\n",
      "Epoch 00085 | Train Accuracy: 0.8989 | Train Loss: 0.4170 | Validation Accuracy: 0.8499 | Validation loss: 0.4611\n",
      "Epoch 00086 | Train Accuracy: 0.8997 | Train Loss: 0.4161 | Validation Accuracy: 0.8505 | Validation loss: 0.4614\n",
      "Epoch 00087 | Train Accuracy: 0.9006 | Train Loss: 0.4153 | Validation Accuracy: 0.8504 | Validation loss: 0.4616\n",
      "Epoch 00088 | Train Accuracy: 0.9015 | Train Loss: 0.4145 | Validation Accuracy: 0.8511 | Validation loss: 0.4619\n",
      "Epoch 00089 | Train Accuracy: 0.9022 | Train Loss: 0.4136 | Validation Accuracy: 0.8516 | Validation loss: 0.4621\n",
      "Epoch 00090 | Train Accuracy: 0.9031 | Train Loss: 0.4128 | Validation Accuracy: 0.8508 | Validation loss: 0.4624\n",
      "Epoch 00091 | Train Accuracy: 0.9042 | Train Loss: 0.4120 | Validation Accuracy: 0.8502 | Validation loss: 0.4627\n",
      "Epoch 00092 | Train Accuracy: 0.9052 | Train Loss: 0.4113 | Validation Accuracy: 0.8494 | Validation loss: 0.4630\n",
      "Epoch 00093 | Train Accuracy: 0.9063 | Train Loss: 0.4105 | Validation Accuracy: 0.8490 | Validation loss: 0.4633\n",
      "Epoch 00094 | Train Accuracy: 0.9069 | Train Loss: 0.4098 | Validation Accuracy: 0.8486 | Validation loss: 0.4635\n",
      "Epoch 00095 | Train Accuracy: 0.9079 | Train Loss: 0.4090 | Validation Accuracy: 0.8485 | Validation loss: 0.4638\n",
      "Epoch 00096 | Train Accuracy: 0.9085 | Train Loss: 0.4083 | Validation Accuracy: 0.8480 | Validation loss: 0.4641\n",
      "Epoch 00097 | Train Accuracy: 0.9091 | Train Loss: 0.4076 | Validation Accuracy: 0.8476 | Validation loss: 0.4644\n",
      "Epoch 00098 | Train Accuracy: 0.9099 | Train Loss: 0.4069 | Validation Accuracy: 0.8473 | Validation loss: 0.4646\n",
      "Epoch 00099 | Train Accuracy: 0.9104 | Train Loss: 0.4062 | Validation Accuracy: 0.8465 | Validation loss: 0.4649\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "\n",
    "print(\"start training...\")\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model.forward(g)\n",
    "    #logits = logits[target_idx]\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc = torch.sum(logits[train_idx].argmax(dim=1) == labels[train_idx])\n",
    "    train_acc = train_acc.item() / len(train_idx)\n",
    "    val_loss = F.cross_entropy(logits[test_idx], labels[test_idx])\n",
    "    val_acc = torch.sum(logits[test_idx].argmax(dim=1) == labels[test_idx])\n",
    "    val_acc = val_acc.item() / len(test_idx)\n",
    "    print(\n",
    "        \"Epoch {:05d} | \".format(epoch)\n",
    "        + \"Train Accuracy: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "            train_acc, loss.item()\n",
    "        )\n",
    "        + \"Validation Accuracy: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "            val_acc, val_loss.item()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e6e3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.7301211548208508\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# After training, when evaluating on test data:\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(g)\n",
    "    probabilities = F.softmax(logits[test_idx], dim=1)  # Convert logits to probabilities\n",
    "    # Assuming your positive class is 1 (adjust accordingly if it's different)\n",
    "    positive_probabilities = probabilities[:, 1]  # Get probabilities for the positive class\n",
    "    # Calculate ROC-AUC\n",
    "    roc_auc = roc_auc_score(labels[test_idx].cpu(), positive_probabilities.cpu())\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9a1d6",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9beb671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolutional NetworkÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185e91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pygod_load_data('reddit')\n",
    "g3 = dgl.graph((reddit.edge_index[0], reddit.edge_index[1]))\n",
    "g3.ndata['feature'] = reddit.x\n",
    "g3.ndata['label'] = reddit.y.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0832ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161c7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example values, adjust based on your dataset\n",
    "in_feats = g3.ndata['feature'].shape[1]\n",
    "h_feats = 16  # Example hidden feature size\n",
    "num_classes = reddit.y.max().item() + 1  # Assuming reddit.y contains class labels starting from 0\n",
    "\n",
    "model = GCN(in_feats, h_feats, int(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de51953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Randomly select 80% of the nodes for training\n",
    "num_nodes = g3.number_of_nodes()\n",
    "num_train = int(num_nodes * 0.8)  # For example, 80% of the nodes for training\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[torch.randperm(num_nodes)[:num_train]] = True\n",
    "\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask[torch.randperm(num_nodes)[num_train:]] = True\n",
    "\n",
    "# Add the train mask to your graph\n",
    "g3.ndata['train_mask'] = train_mask\n",
    "g3.ndata['val_mask'] = val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaf5460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Train Accuracy: 0.9654 | Train Loss: 0.6761 | Validation Accuracy: 0.9677 | Validation loss: 0.6392\n",
      "Epoch 00001 | Train Accuracy: 0.9654 | Train Loss: 0.6393 | Validation Accuracy: 0.9677 | Validation loss: 0.6071\n",
      "Epoch 00002 | Train Accuracy: 0.9654 | Train Loss: 0.6073 | Validation Accuracy: 0.9677 | Validation loss: 0.5776\n",
      "Epoch 00003 | Train Accuracy: 0.9654 | Train Loss: 0.5778 | Validation Accuracy: 0.9677 | Validation loss: 0.5490\n",
      "Epoch 00004 | Train Accuracy: 0.9654 | Train Loss: 0.5494 | Validation Accuracy: 0.9677 | Validation loss: 0.5209\n",
      "Epoch 00005 | Train Accuracy: 0.9654 | Train Loss: 0.5214 | Validation Accuracy: 0.9677 | Validation loss: 0.4934\n",
      "Epoch 00006 | Train Accuracy: 0.9654 | Train Loss: 0.4940 | Validation Accuracy: 0.9677 | Validation loss: 0.4666\n",
      "Epoch 00007 | Train Accuracy: 0.9654 | Train Loss: 0.4673 | Validation Accuracy: 0.9677 | Validation loss: 0.4406\n",
      "Epoch 00008 | Train Accuracy: 0.9654 | Train Loss: 0.4415 | Validation Accuracy: 0.9677 | Validation loss: 0.4155\n",
      "Epoch 00009 | Train Accuracy: 0.9654 | Train Loss: 0.4165 | Validation Accuracy: 0.9677 | Validation loss: 0.3914\n",
      "Epoch 00010 | Train Accuracy: 0.9654 | Train Loss: 0.3926 | Validation Accuracy: 0.9677 | Validation loss: 0.3685\n",
      "Epoch 00011 | Train Accuracy: 0.9654 | Train Loss: 0.3698 | Validation Accuracy: 0.9677 | Validation loss: 0.3467\n",
      "Epoch 00012 | Train Accuracy: 0.9654 | Train Loss: 0.3482 | Validation Accuracy: 0.9677 | Validation loss: 0.3263\n",
      "Epoch 00013 | Train Accuracy: 0.9654 | Train Loss: 0.3279 | Validation Accuracy: 0.9677 | Validation loss: 0.3071\n",
      "Epoch 00014 | Train Accuracy: 0.9654 | Train Loss: 0.3089 | Validation Accuracy: 0.9677 | Validation loss: 0.2893\n",
      "Epoch 00015 | Train Accuracy: 0.9654 | Train Loss: 0.2913 | Validation Accuracy: 0.9677 | Validation loss: 0.2729\n",
      "Epoch 00016 | Train Accuracy: 0.9654 | Train Loss: 0.2750 | Validation Accuracy: 0.9677 | Validation loss: 0.2579\n",
      "Epoch 00017 | Train Accuracy: 0.9654 | Train Loss: 0.2601 | Validation Accuracy: 0.9677 | Validation loss: 0.2441\n",
      "Epoch 00018 | Train Accuracy: 0.9654 | Train Loss: 0.2465 | Validation Accuracy: 0.9677 | Validation loss: 0.2318\n",
      "Epoch 00019 | Train Accuracy: 0.9654 | Train Loss: 0.2343 | Validation Accuracy: 0.9677 | Validation loss: 0.2206\n",
      "Epoch 00020 | Train Accuracy: 0.9654 | Train Loss: 0.2233 | Validation Accuracy: 0.9677 | Validation loss: 0.2108\n",
      "Epoch 00021 | Train Accuracy: 0.9654 | Train Loss: 0.2136 | Validation Accuracy: 0.9677 | Validation loss: 0.2020\n",
      "Epoch 00022 | Train Accuracy: 0.9654 | Train Loss: 0.2050 | Validation Accuracy: 0.9677 | Validation loss: 0.1944\n",
      "Epoch 00023 | Train Accuracy: 0.9654 | Train Loss: 0.1974 | Validation Accuracy: 0.9677 | Validation loss: 0.1877\n",
      "Epoch 00024 | Train Accuracy: 0.9654 | Train Loss: 0.1909 | Validation Accuracy: 0.9677 | Validation loss: 0.1820\n",
      "Epoch 00025 | Train Accuracy: 0.9654 | Train Loss: 0.1853 | Validation Accuracy: 0.9677 | Validation loss: 0.1771\n",
      "Epoch 00026 | Train Accuracy: 0.9654 | Train Loss: 0.1806 | Validation Accuracy: 0.9677 | Validation loss: 0.1729\n",
      "Epoch 00027 | Train Accuracy: 0.9654 | Train Loss: 0.1765 | Validation Accuracy: 0.9677 | Validation loss: 0.1695\n",
      "Epoch 00028 | Train Accuracy: 0.9654 | Train Loss: 0.1732 | Validation Accuracy: 0.9677 | Validation loss: 0.1666\n",
      "Epoch 00029 | Train Accuracy: 0.9654 | Train Loss: 0.1704 | Validation Accuracy: 0.9677 | Validation loss: 0.1642\n",
      "Epoch 00030 | Train Accuracy: 0.9654 | Train Loss: 0.1682 | Validation Accuracy: 0.9677 | Validation loss: 0.1623\n",
      "Epoch 00031 | Train Accuracy: 0.9654 | Train Loss: 0.1664 | Validation Accuracy: 0.9677 | Validation loss: 0.1608\n",
      "Epoch 00032 | Train Accuracy: 0.9654 | Train Loss: 0.1650 | Validation Accuracy: 0.9677 | Validation loss: 0.1597\n",
      "Epoch 00033 | Train Accuracy: 0.9654 | Train Loss: 0.1640 | Validation Accuracy: 0.9677 | Validation loss: 0.1588\n",
      "Epoch 00034 | Train Accuracy: 0.9654 | Train Loss: 0.1632 | Validation Accuracy: 0.9677 | Validation loss: 0.1581\n",
      "Epoch 00035 | Train Accuracy: 0.9654 | Train Loss: 0.1626 | Validation Accuracy: 0.9677 | Validation loss: 0.1576\n",
      "Epoch 00036 | Train Accuracy: 0.9654 | Train Loss: 0.1622 | Validation Accuracy: 0.9677 | Validation loss: 0.1573\n",
      "Epoch 00037 | Train Accuracy: 0.9654 | Train Loss: 0.1620 | Validation Accuracy: 0.9677 | Validation loss: 0.1571\n",
      "Epoch 00038 | Train Accuracy: 0.9654 | Train Loss: 0.1619 | Validation Accuracy: 0.9677 | Validation loss: 0.1570\n",
      "Epoch 00039 | Train Accuracy: 0.9654 | Train Loss: 0.1619 | Validation Accuracy: 0.9677 | Validation loss: 0.1570\n",
      "Epoch 00040 | Train Accuracy: 0.9654 | Train Loss: 0.1619 | Validation Accuracy: 0.9677 | Validation loss: 0.1570\n",
      "Epoch 00041 | Train Accuracy: 0.9654 | Train Loss: 0.1620 | Validation Accuracy: 0.9677 | Validation loss: 0.1571\n",
      "Epoch 00042 | Train Accuracy: 0.9654 | Train Loss: 0.1621 | Validation Accuracy: 0.9677 | Validation loss: 0.1572\n",
      "Epoch 00043 | Train Accuracy: 0.9654 | Train Loss: 0.1623 | Validation Accuracy: 0.9677 | Validation loss: 0.1573\n",
      "Epoch 00044 | Train Accuracy: 0.9654 | Train Loss: 0.1624 | Validation Accuracy: 0.9677 | Validation loss: 0.1574\n",
      "Epoch 00045 | Train Accuracy: 0.9654 | Train Loss: 0.1625 | Validation Accuracy: 0.9677 | Validation loss: 0.1575\n",
      "Epoch 00046 | Train Accuracy: 0.9654 | Train Loss: 0.1627 | Validation Accuracy: 0.9677 | Validation loss: 0.1576\n",
      "Epoch 00047 | Train Accuracy: 0.9654 | Train Loss: 0.1628 | Validation Accuracy: 0.9677 | Validation loss: 0.1577\n",
      "Epoch 00048 | Train Accuracy: 0.9654 | Train Loss: 0.1629 | Validation Accuracy: 0.9677 | Validation loss: 0.1577\n",
      "Epoch 00049 | Train Accuracy: 0.9654 | Train Loss: 0.1630 | Validation Accuracy: 0.9677 | Validation loss: 0.1578\n",
      "Epoch 00050 | Train Accuracy: 0.9654 | Train Loss: 0.1630 | Validation Accuracy: 0.9677 | Validation loss: 0.1578\n",
      "Epoch 00051 | Train Accuracy: 0.9654 | Train Loss: 0.1631 | Validation Accuracy: 0.9677 | Validation loss: 0.1578\n",
      "Epoch 00052 | Train Accuracy: 0.9654 | Train Loss: 0.1631 | Validation Accuracy: 0.9677 | Validation loss: 0.1578\n",
      "Epoch 00053 | Train Accuracy: 0.9654 | Train Loss: 0.1631 | Validation Accuracy: 0.9677 | Validation loss: 0.1577\n",
      "Epoch 00054 | Train Accuracy: 0.9654 | Train Loss: 0.1630 | Validation Accuracy: 0.9677 | Validation loss: 0.1577\n",
      "Epoch 00055 | Train Accuracy: 0.9654 | Train Loss: 0.1630 | Validation Accuracy: 0.9677 | Validation loss: 0.1577\n",
      "Epoch 00056 | Train Accuracy: 0.9654 | Train Loss: 0.1629 | Validation Accuracy: 0.9677 | Validation loss: 0.1576\n",
      "Epoch 00057 | Train Accuracy: 0.9654 | Train Loss: 0.1629 | Validation Accuracy: 0.9677 | Validation loss: 0.1575\n",
      "Epoch 00058 | Train Accuracy: 0.9654 | Train Loss: 0.1628 | Validation Accuracy: 0.9677 | Validation loss: 0.1574\n",
      "Epoch 00059 | Train Accuracy: 0.9654 | Train Loss: 0.1627 | Validation Accuracy: 0.9677 | Validation loss: 0.1573\n",
      "Epoch 00060 | Train Accuracy: 0.9654 | Train Loss: 0.1626 | Validation Accuracy: 0.9677 | Validation loss: 0.1573\n",
      "Epoch 00061 | Train Accuracy: 0.9654 | Train Loss: 0.1625 | Validation Accuracy: 0.9677 | Validation loss: 0.1572\n",
      "Epoch 00062 | Train Accuracy: 0.9654 | Train Loss: 0.1624 | Validation Accuracy: 0.9677 | Validation loss: 0.1571\n",
      "Epoch 00063 | Train Accuracy: 0.9654 | Train Loss: 0.1623 | Validation Accuracy: 0.9677 | Validation loss: 0.1570\n",
      "Epoch 00064 | Train Accuracy: 0.9654 | Train Loss: 0.1622 | Validation Accuracy: 0.9677 | Validation loss: 0.1569\n",
      "Epoch 00065 | Train Accuracy: 0.9654 | Train Loss: 0.1621 | Validation Accuracy: 0.9677 | Validation loss: 0.1568\n",
      "Epoch 00066 | Train Accuracy: 0.9654 | Train Loss: 0.1620 | Validation Accuracy: 0.9677 | Validation loss: 0.1567\n",
      "Epoch 00067 | Train Accuracy: 0.9654 | Train Loss: 0.1619 | Validation Accuracy: 0.9677 | Validation loss: 0.1566\n",
      "Epoch 00068 | Train Accuracy: 0.9654 | Train Loss: 0.1618 | Validation Accuracy: 0.9677 | Validation loss: 0.1566\n",
      "Epoch 00069 | Train Accuracy: 0.9654 | Train Loss: 0.1617 | Validation Accuracy: 0.9677 | Validation loss: 0.1565\n",
      "Epoch 00070 | Train Accuracy: 0.9654 | Train Loss: 0.1616 | Validation Accuracy: 0.9677 | Validation loss: 0.1564\n",
      "Epoch 00071 | Train Accuracy: 0.9654 | Train Loss: 0.1615 | Validation Accuracy: 0.9677 | Validation loss: 0.1564\n",
      "Epoch 00072 | Train Accuracy: 0.9654 | Train Loss: 0.1615 | Validation Accuracy: 0.9677 | Validation loss: 0.1563\n",
      "Epoch 00073 | Train Accuracy: 0.9654 | Train Loss: 0.1614 | Validation Accuracy: 0.9677 | Validation loss: 0.1563\n",
      "Epoch 00074 | Train Accuracy: 0.9654 | Train Loss: 0.1613 | Validation Accuracy: 0.9677 | Validation loss: 0.1562\n",
      "Epoch 00075 | Train Accuracy: 0.9654 | Train Loss: 0.1613 | Validation Accuracy: 0.9677 | Validation loss: 0.1562\n",
      "Epoch 00076 | Train Accuracy: 0.9654 | Train Loss: 0.1612 | Validation Accuracy: 0.9677 | Validation loss: 0.1561\n",
      "Epoch 00077 | Train Accuracy: 0.9654 | Train Loss: 0.1612 | Validation Accuracy: 0.9677 | Validation loss: 0.1561\n",
      "Epoch 00078 | Train Accuracy: 0.9654 | Train Loss: 0.1612 | Validation Accuracy: 0.9677 | Validation loss: 0.1561\n",
      "Epoch 00079 | Train Accuracy: 0.9654 | Train Loss: 0.1611 | Validation Accuracy: 0.9677 | Validation loss: 0.1561\n",
      "Epoch 00080 | Train Accuracy: 0.9654 | Train Loss: 0.1611 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00081 | Train Accuracy: 0.9654 | Train Loss: 0.1611 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00082 | Train Accuracy: 0.9654 | Train Loss: 0.1610 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00083 | Train Accuracy: 0.9654 | Train Loss: 0.1610 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00084 | Train Accuracy: 0.9654 | Train Loss: 0.1610 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00085 | Train Accuracy: 0.9654 | Train Loss: 0.1610 | Validation Accuracy: 0.9677 | Validation loss: 0.1560\n",
      "Epoch 00086 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00087 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00088 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00089 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00090 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00091 | Train Accuracy: 0.9654 | Train Loss: 0.1609 | Validation Accuracy: 0.9677 | Validation loss: 0.1559\n",
      "Epoch 00092 | Train Accuracy: 0.9654 | Train Loss: 0.1608 | Validation Accuracy: 0.9677 | Validation loss: 0.1558\n",
      "Epoch 00093 | Train Accuracy: 0.9654 | Train Loss: 0.1608 | Validation Accuracy: 0.9677 | Validation loss: 0.1558\n",
      "Epoch 00094 | Train Accuracy: 0.9654 | Train Loss: 0.1608 | Validation Accuracy: 0.9677 | Validation loss: 0.1558\n",
      "Epoch 00095 | Train Accuracy: 0.9654 | Train Loss: 0.1608 | Validation Accuracy: 0.9677 | Validation loss: 0.1558\n",
      "Epoch 00096 | Train Accuracy: 0.9654 | Train Loss: 0.1608 | Validation Accuracy: 0.9677 | Validation loss: 0.1558\n",
      "Epoch 00097 | Train Accuracy: 0.9654 | Train Loss: 0.1607 | Validation Accuracy: 0.9677 | Validation loss: 0.1557\n",
      "Epoch 00098 | Train Accuracy: 0.9654 | Train Loss: 0.1607 | Validation Accuracy: 0.9677 | Validation loss: 0.1557\n",
      "Epoch 00099 | Train Accuracy: 0.9654 | Train Loss: 0.1607 | Validation Accuracy: 0.9677 | Validation loss: 0.1557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):  # Example number of epochs\n",
    "    model.train()\n",
    "    logits = model(g3, g3.ndata['feature'])\n",
    "    train_loss = F.cross_entropy(logits[g3.ndata['train_mask']], g3.ndata['label'][g3.ndata['train_mask']])\n",
    "    \n",
    "    # Compute training accuracy\n",
    "    _, train_preds = torch.max(logits[g3.ndata['train_mask']], 1)\n",
    "    train_acc = accuracy_score(g3.ndata['label'][g3.ndata['train_mask']].cpu().numpy(), train_preds.cpu().numpy())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g3, g3.ndata['feature'])\n",
    "        val_loss = F.cross_entropy(logits[g3.ndata['val_mask']], g3.ndata['label'][g3.ndata['val_mask']])\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        _, val_preds = torch.max(logits[g3.ndata['val_mask']], 1)\n",
    "        val_acc = accuracy_score(g3.ndata['label'][g3.ndata['val_mask']].cpu().numpy(), val_preds.cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        \"Epoch {:05d} | \".format(epoch)\n",
    "        + \"Train Accuracy: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "            train_acc, train_loss.item()\n",
    "        )\n",
    "        + \"Validation Accuracy: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "            val_acc, val_loss.item()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e4e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.44279231743351627\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# After training, when evaluating on test data:\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(g)\n",
    "    probabilities = F.softmax(logits[test_idx], dim=1)  # Convert logits to probabilities\n",
    "    # Assuming your positive class is 1 (adjust accordingly if it's different)\n",
    "    positive_probabilities = probabilities[:, 1]  # Get probabilities for the positive class\n",
    "    # Calculate ROC-AUC\n",
    "    roc_auc = roc_auc_score(labels[test_idx].cpu(), positive_probabilities.cpu())\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a0647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
